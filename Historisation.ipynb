{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, current_timestamp\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"CustomerHistorization\").getOrCreate()\n",
    "\n",
    "# Simulate an initial load of customer data\n",
    "initial_data = [\n",
    "    (1, 'Alice', 'alice@example.com'),\n",
    "    (2, 'Bob', 'bob@example.com'),\n",
    "    (3, 'Charlie', 'charlie@example.com'),\n",
    "    (6, 'Frank', 'frank@example.com'),\n",
    "]\n",
    "\n",
    "columns = [\"CustomerID\", \"Name\", \"Email\"]\n",
    "\n",
    "df = spark.createDataFrame(initial_data, columns)\n",
    "\n",
    "\n",
    "# Simulate changes in the data (updates)\n",
    "# TODO: Inner join between df and incoming_df\n",
    "changes_data = [\n",
    "    (1, 'Alice', 'alice.new@example.com'),\n",
    "    (3, 'Chandler','charlie@example.com'),\n",
    "]\n",
    "\n",
    "changes_df = spark.createDataFrame(changes_data, columns)\n",
    "\n",
    "# Load incremental data (e.g., new customers)\n",
    "# TODO: remaining rows from incoming df\n",
    "incremental_data = [(4, 'David', 'david@example.com'),\n",
    "                    (5, 'Eva', 'eva@example.com')]\n",
    "\n",
    "incremental_df = spark.createDataFrame(incremental_data, columns)\n",
    "\n",
    "\n",
    "# Simulate deletions\n",
    "deletions = [\n",
    "    2,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the update df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------------------+------------+--------------------+\n",
      "|CustomerID|   Name|              Email|  ChangeType|           Timestamp|\n",
      "+----------+-------+-------------------+------------+--------------------+\n",
      "|         2|    Bob|    bob@example.com|    Deletion|2023-08-21 15:27:...|\n",
      "|         1|  Alice|  alice@example.com|Modification|2023-08-21 15:27:...|\n",
      "|         3|Charlie|charlie@example.com|Modification|2023-08-21 15:27:...|\n",
      "|         4|   null|               null|    Addition|2023-08-21 15:27:...|\n",
      "|         5|   null|               null|    Addition|2023-08-21 15:27:...|\n",
      "+----------+-------+-------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for the update record\n",
    "\n",
    "# Record deletion operations\n",
    "update = (\n",
    "    df\n",
    "    .filter(F.col(\"CustomerID\").isin(deletions))\n",
    "    .withColumn(\"ChangeType\", lit(\"Deletion\"))\n",
    ")\n",
    "\n",
    "# Record modification operations\n",
    "update = (\n",
    "    update\n",
    "    .unionByName(\n",
    "        df\n",
    "        .join(changes_df, [\"CustomerID\"], \"leftsemi\")\n",
    "        .withColumn(\"ChangeType\", lit(\"Modification\"))   \n",
    "    )\n",
    ")\n",
    "\n",
    "# Record addition operations (new row)\n",
    "# All columns are not needed just the keys\n",
    "copy_incremental_df = incremental_df\n",
    "\n",
    "null_cols = [x for x in columns if x != \"CustomerID\"]\n",
    "for col in null_cols:\n",
    "    copy_incremental_df = copy_incremental_df.withColumn(col, F.lit(None))\n",
    "\n",
    "update = (\n",
    "    update\n",
    "    .unionByName(\n",
    "        copy_incremental_df\n",
    "        .withColumn(\"ChangeType\", lit(\"Addition\"))\n",
    "    )\n",
    "    \n",
    ")\n",
    "\n",
    "# Add timestamp\n",
    "update = update.withColumn(\"Timestamp\", current_timestamp())\n",
    "\n",
    "update.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|CustomerID|    Name|               Email|\n",
      "+----------+--------+--------------------+\n",
      "|         6|   Frank|   frank@example.com|\n",
      "|         1|   Alice|alice.new@example...|\n",
      "|         3|Chandler| charlie@example.com|\n",
      "|         4|   David|   david@example.com|\n",
      "|         5|     Eva|     eva@example.com|\n",
      "+----------+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deletions\n",
    "df = df.filter(~F.col(\"CustomerID\").isin(deletions))\n",
    "\n",
    "# Modifications\n",
    "df = (\n",
    "    df\n",
    "    .join(changes_df, [\"CustomerID\"], \"leftanti\")\n",
    "    .unionByName(changes_df)\n",
    ")\n",
    "\n",
    "# Additions\n",
    "df = df.unionByName(incremental_df)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------------------+\n",
      "|CustomerID|   Name|              Email|\n",
      "+----------+-------+-------------------+\n",
      "|         6|  Frank|  frank@example.com|\n",
      "|         1|  Alice|  alice@example.com|\n",
      "|         3|Charlie|charlie@example.com|\n",
      "|         2|    Bob|    bob@example.com|\n",
      "+----------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reverse additions\n",
    "df = (\n",
    "    df\n",
    "    .join(update.filter(F.col(\"ChangeType\") == \"Addition\").select(*columns), [\"CustomerID\"], \"leftanti\")\n",
    ")\n",
    "\n",
    "# Reverse modifications\n",
    "changes_df = update.filter(F.col(\"ChangeType\") == \"Modification\").select(*columns)\n",
    "df = (\n",
    "    df\n",
    "    .join(changes_df, [\"CustomerID\"], \"leftanti\")\n",
    "    .unionByName(changes_df)\n",
    ")\n",
    "\n",
    "# Reverse deletions\n",
    "df = (\n",
    "    df\n",
    "    .unionByName(update.filter(F.col(\"ChangeType\") == \"Deletion\").select(*columns))\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyspark)",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
